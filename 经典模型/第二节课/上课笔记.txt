决策树
熵不纯度，我记得是哪个树来着，对叶子节点越多有很大的倾向来着
基于基尼指数的信息增益和相对信息增益有什么区别

上课回顾了之前三个决策树模型，不过没讲哪个是ID3，哪个是C4.5，还有CART树
CART树是用来处理连续的数据的（我印象里是这么用的）



树：
先是找到信息增益最大的索引
前提：计算增益的前提就是对树节点进行划分，划分的代码已经写好了
前提，怎么进行划分

用for 循环遍历 每一个特征进行计算，但是每个特征的值怎么区分。用字典
创建字典保存特征值的名字和数量，来计算信息增益

写完计算最大信息增益的索引的时候用到的表分离可以分离出去感觉，毕竟之后递归的时候会调用到这个代码
需要：
1. 分离后再次找特征值
2. 再次调用分离表函数

所以不用分离出函数了

递归：
递归结束的条件是什么？
1. 递归到所有样本属于一个类别，则该类别为叶子节点
2. 递归到没有特征可以划分了，则该类别为叶子节点
